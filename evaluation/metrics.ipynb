{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path += ['../utils']\n",
    "import csv\n",
    "from tqdm import tqdm \n",
    "import collections\n",
    "from collections import defaultdict\n",
    "import math\n",
    "import gzip\n",
    "import pickle\n",
    "import numpy as np\n",
    "import faiss\n",
    "import os\n",
    "import pytrec_eval\n",
    "import json\n",
    "import time\n",
    "from msmarco_eval import quality_checks_qids, compute_metrics, load_reference\n",
    "\n",
    "\n",
    "use_gpu_faiss = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_string_id(result_dict):\n",
    "    string_id_dict = {}\n",
    "\n",
    "    # format [string, dict[string, val]]\n",
    "    for k, v in result_dict.items():\n",
    "        _temp_v = {}\n",
    "        for inner_k, inner_v in v.items():\n",
    "            _temp_v[str(inner_k)] = inner_v\n",
    "\n",
    "        string_id_dict[str(k)] = _temp_v\n",
    "\n",
    "    return string_id_dict\n",
    "\n",
    "\n",
    "def dump_query_scores(run_files_dir, fname, results, r_qidmap):\n",
    "    out_f = os.path.join(run_files_dir, f'query_scores.{fname}.txt')\n",
    "    os.makedirs(run_files_dir, exist_ok=True)\n",
    "    with open(out_f, 'w') as fout:\n",
    "        print('MF_Qid\\tPP_Qid\\tndcg@10', file=fout)\n",
    "        for k, v in results.items():\n",
    "            print(f\"{r_qidmap[int(k)]}\\t{k}\\t{v['ndcg_cut_10']}\", file=fout)\n",
    "\n",
    "\n",
    "def EvalDevQuery(query_embedding2id, passage_embedding2id, dev_query_positive_id, I_nearest_neighbor,\n",
    "                 r_qidmap, r_pidmap,\n",
    "                 topN, run_files_dir, shortcut=False, cuts=None):\n",
    "    prediction = {} #[qid][docid] = docscore, here we use -rank as score, so the higher the rank (1 > 2), the higher the score (-1 > -2)\n",
    "\n",
    "    total_5 = 0\n",
    "    labeled_5 = 0\n",
    "    total_20 = 0\n",
    "    labeled_20 = 0\n",
    "    total_100 = 0\n",
    "    labeled_100 = 0\n",
    "    Atotal = 0\n",
    "    Alabeled = 0\n",
    "    qids_to_ranked_candidate_passages = {}\n",
    "    for query_idx in range(len(I_nearest_neighbor)): \n",
    "        seen_pid = set()\n",
    "        query_id = query_embedding2id[query_idx]\n",
    "        prediction[query_id] = {}\n",
    "        \n",
    "\n",
    "        top_ann_pid = I_nearest_neighbor[query_idx].copy()\n",
    "        selected_ann_idx = top_ann_pid[:topN]\n",
    "        rank = 0\n",
    "        \n",
    "        if query_id in qids_to_ranked_candidate_passages:\n",
    "            pass    \n",
    "        else:\n",
    "            # By default, all PIDs in the list of 1000 are 0. Only override those that are given\n",
    "            tmp = [0] * 1000\n",
    "            qids_to_ranked_candidate_passages[query_id] = tmp\n",
    "                \n",
    "        for idx in selected_ann_idx:\n",
    "            pred_pid = passage_embedding2id[idx]\n",
    "            \n",
    "            if not pred_pid in seen_pid:\n",
    "                # this check handles multiple vector per document\n",
    "                qids_to_ranked_candidate_passages[query_id][rank]=pred_pid\n",
    "                Atotal += 1\n",
    "                \n",
    "                if not shortcut:\n",
    "                    if pred_pid not in dev_query_positive_id[query_id]:\n",
    "                        Alabeled += 1\n",
    "                    if rank < 5:\n",
    "                        total_5 += 1\n",
    "                        if pred_pid not in dev_query_positive_id[query_id]:\n",
    "                            labeled_5 += 1\n",
    "                    if rank < 20:\n",
    "                        total_20 += 1\n",
    "                        if pred_pid not in dev_query_positive_id[query_id]:\n",
    "                            labeled_20 += 1\n",
    "                    if rank < 100:\n",
    "                        total_100 += 1\n",
    "                        if pred_pid not in dev_query_positive_id[query_id]:\n",
    "                            labeled_100 += 1\n",
    "                            \n",
    "                rank += 1\n",
    "                if not (task=='arguana' and r_qidmap[query_id]==r_pidmap[pred_pid]):\n",
    "                    prediction[query_id][pred_pid] = -rank\n",
    "                seen_pid.add(pred_pid)\n",
    "        \n",
    "    if shortcut:\n",
    "        return [prediction] + [None]*15\n",
    "    # use out of the box evaluation script\n",
    "    evaluator = pytrec_eval.RelevanceEvaluator(\n",
    "        convert_to_string_id(dev_query_positive_id), {'map_cut', 'ndcg_cut', 'recip_rank','recall', 'P'})\n",
    "\n",
    "    eval_query_cnt = 0\n",
    "    result = evaluator.evaluate(convert_to_string_id(prediction))\n",
    "    dump_query_scores(run_files_dir, ckpt_choice.replace('/', '__'), result, r_qidmap)\n",
    "    \n",
    "    qids_to_relevant_passageids = {}\n",
    "    for qid in dev_query_positive_id:\n",
    "        qid = int(qid)\n",
    "        if qid in qids_to_relevant_passageids:\n",
    "            pass\n",
    "        else:\n",
    "            qids_to_relevant_passageids[qid] = []\n",
    "            for pid in dev_query_positive_id[qid]:\n",
    "                if pid>0:\n",
    "                    qids_to_relevant_passageids[qid].append(pid)\n",
    "            \n",
    "    ms_mrr = compute_metrics(qids_to_relevant_passageids, qids_to_ranked_candidate_passages)\n",
    "\n",
    "    ndcg = defaultdict(int)\n",
    "    precision = defaultdict(int)\n",
    "    Map = defaultdict(int)\n",
    "    mrr = 0\n",
    "    recall = 0\n",
    "    recall_100 = 0\n",
    "    recall_10 = 0\n",
    "\n",
    "    for k in result.keys():\n",
    "        eval_query_cnt += 1\n",
    "        for cut in cuts:\n",
    "            ndcg[cut] += result[k][f\"ndcg_cut_{cut}\"]\n",
    "            precision[cut] += result[k][f\"P_{cut}\"]\n",
    "            Map[cut] += result[k][f\"map_cut_{cut}\"]\n",
    "        mrr += result[k][\"recip_rank\"]\n",
    "        recall += result[k][\"recall_\"+str(topN)]\n",
    "        recall_100 += result[k][\"recall_100\"]\n",
    "        recall_10 += result[k][\"recall_10\"]\n",
    "\n",
    "    final_ndcg, final_precision, final_Map = {}, {}, {}\n",
    "    for cut in cuts:\n",
    "        final_ndcg[cut] = ndcg[cut] / eval_query_cnt\n",
    "        final_precision[cut] = precision[cut] / eval_query_cnt\n",
    "        final_Map[cut] = Map[cut] / eval_query_cnt\n",
    "    final_mrr = mrr / eval_query_cnt\n",
    "    final_recall = recall / eval_query_cnt\n",
    "    final_recall_100 = recall_100 / eval_query_cnt\n",
    "    final_recall_10 = recall_10 / eval_query_cnt\n",
    "    hole_rate_5 = labeled_5 / total_5\n",
    "    hole_rate_20 = labeled_20 / total_20\n",
    "    hole_rate_100 = labeled_100 / total_100\n",
    "    Ahole_rate = Alabeled/Atotal\n",
    "    \n",
    "    return (prediction, final_ndcg, final_precision,\n",
    "            eval_query_cnt, final_Map, final_mrr, final_recall, final_recall_100, final_recall_10,\n",
    "            hole_rate_5, hole_rate_20, hole_rate_100, ms_mrr, Ahole_rate, result, prediction)\n",
    "\n",
    "\n",
    "def dump_pred_to_trecrun(prediction, run_files_dir, run_type, r_qidmap, r_pidmap):\n",
    "    mf_prediction = {  # marco-format prediction\n",
    "        r_qidmap[qid]: {r_pidmap[k]: v for k,v in values.items()}\n",
    "        for qid, values in prediction.items()\n",
    "    }\n",
    "\n",
    "    # dump it as trec run file\n",
    "    os.makedirs(run_files_dir, exist_ok=True)\n",
    "    out_f = os.path.join(run_files_dir, f'runs.{run_type}.txt')\n",
    "#     print('Dump to', out_f)\n",
    "    with open(out_f, 'w') as fout:\n",
    "        for qid, qpreds in mf_prediction.items():\n",
    "            for pid, score in qpreds.items():\n",
    "                print(f'{qid} Q0 {pid} {-score} {score} TEAM', file=fout)\n",
    "    return out_f\n",
    "\n",
    "\n",
    "def faiss_search_with_gpu_partitioning(passages, queries, topN):\n",
    "    p_size = int(1000000)\n",
    "    partition_results = []\n",
    "    for i_p in range(math.ceil(passages.shape[0] / p_size)):\n",
    "        cpu_index = faiss.IndexFlatIP(dim)\n",
    "        gpu_index = faiss.index_cpu_to_all_gpus(cpu_index)\n",
    "        current_passages = passages[i_p*p_size : (i_p+1)*p_size]\n",
    "        print(i_p, current_passages.shape)\n",
    "        start_time = time.time()\n",
    "        gpu_index.add(current_passages)\n",
    "        partition_results.append(gpu_index.search(queries, topN))\n",
    "        print(time.time() - start_time)\n",
    "        del cpu_index\n",
    "        del gpu_index\n",
    "    \n",
    "    # merge\n",
    "    collection = []\n",
    "    for i_p in range(len(partition_results)):\n",
    "        collection.append(np.dstack([\n",
    "            partition_results[i_p][0],\n",
    "            partition_results[i_p][1] + p_size*i_p  # fix the offset\n",
    "        ]))  # [query, passage, DISTANCE/PID]\n",
    "    print('end of stacking'); del partition_results\n",
    "    collection = np.concatenate(collection, axis=1)\n",
    "    print('end of concat')\n",
    "    \n",
    "    results = []\n",
    "    for i, query_result in enumerate(collection):\n",
    "        if i%10000 == 0:\n",
    "            print(i)\n",
    "        results.append([int(x[1]) for x in sorted(query_result, key=lambda x: x[0], reverse=True)[:topN]])\n",
    "    \n",
    "    return None, np.array(results)         \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# end2end eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def end2end(\n",
    "    task,\n",
    "    data_type,\n",
    "    processed_data_dir,\n",
    "    marcoformat_data_dir,\n",
    "    run_files_dir,\n",
    "    checkpoint_path,\n",
    "    verbose\n",
    "):\n",
    "    # load qrel\n",
    "    if data_type == 0:\n",
    "        topN = 100\n",
    "    else:\n",
    "        topN = 1000\n",
    "    dev_query_positive_id = {}\n",
    "\n",
    "    query_positive_id_path = os.path.join(processed_data_dir, \"dev-qrel.tsv\")\n",
    "    if verbose:\n",
    "        print(query_positive_id_path)\n",
    "\n",
    "    with open(query_positive_id_path, 'r', encoding='utf8') as f:\n",
    "        tsvreader = csv.reader(f, delimiter=\"\\t\")\n",
    "        for [topicid, docid, rel] in tsvreader:\n",
    "            topicid = int(topicid)\n",
    "            docid = int(docid)\n",
    "            if topicid not in dev_query_positive_id:\n",
    "                dev_query_positive_id[topicid] = {}\n",
    "            rel_score = max(int(rel), 0)\n",
    "            dev_query_positive_id[topicid][docid] = rel_score\n",
    "    \n",
    "    \n",
    "    # load mapping\n",
    "    qidmap_path = processed_data_dir+\"/qid2offset.pickle\"\n",
    "    pidmap_path = processed_data_dir+\"/pid2offset.pickle\"\n",
    "\n",
    "    with open(qidmap_path, 'rb') as handle:\n",
    "        qidmap = pickle.load(handle)\n",
    "\n",
    "    with open(pidmap_path, 'rb') as handle:\n",
    "        pidmap = pickle.load(handle)\n",
    "\n",
    "    r_qidmap = {v: k for k,v in qidmap.items()}\n",
    "    r_pidmap = {v: k for k,v in pidmap.items()}\n",
    "    \n",
    "    \n",
    "    # load embeddings\n",
    "    if task=='fulltreccovid':\n",
    "        checkpoint_path = checkpoint_path.replace('fulltreccovid-ann', 'beirtreccovid-ann')\n",
    "    dev_query_embedding = []\n",
    "    dev_query_embedding2id = []\n",
    "    passage_embedding = []\n",
    "    passage_embedding2id = []\n",
    "    for i in range(8):\n",
    "        try:\n",
    "            with open(checkpoint_path + \"dev_query_0__emb_p__data_obj_\"+str(i)+\".pb\", 'rb') as handle:\n",
    "                dev_query_embedding.append(pickle.load(handle))\n",
    "            with open(checkpoint_path + \"dev_query_0__embid_p__data_obj_\"+str(i)+\".pb\", 'rb') as handle:\n",
    "                dev_query_embedding2id.append(pickle.load(handle))\n",
    "            with open(checkpoint_path + \"passage_0__emb_p__data_obj_\"+str(i)+\".pb\", 'rb') as handle:\n",
    "                passage_embedding.append(pickle.load(handle))\n",
    "            with open(checkpoint_path + \"passage_0__embid_p__data_obj_\"+str(i)+\".pb\", 'rb') as handle:\n",
    "                passage_embedding2id.append(pickle.load(handle))\n",
    "        except FileNotFoundError:\n",
    "            break\n",
    "        if verbose:\n",
    "            print(i)\n",
    "    if verbose:\n",
    "        print(checkpoint_path + \"dev_query_0__emb_p__data_obj_\"+str(i)+\".pb\")\n",
    "    if (not dev_query_embedding) or (not dev_query_embedding2id) or (not passage_embedding) or not (passage_embedding2id):\n",
    "        print(\"No data found for checkpoint\")\n",
    "\n",
    "    dev_query_embedding = np.concatenate(dev_query_embedding, axis=0)\n",
    "    dev_query_embedding2id = np.concatenate(dev_query_embedding2id, axis=0)\n",
    "    passage_embedding = np.concatenate(passage_embedding, axis=0)\n",
    "    passage_embedding2id = np.concatenate(passage_embedding2id, axis=0)\n",
    "    \n",
    "    \n",
    "    # search\n",
    "    if verbose:\n",
    "        print('search')\n",
    "        print(passage_embedding.shape, dev_query_embedding.shape)\n",
    "    dim = passage_embedding.shape[1]\n",
    "    faiss.omp_set_num_threads(64)\n",
    "    if not use_gpu_faiss:\n",
    "        cpu_index = faiss.IndexFlatIP(dim)\n",
    "        start_time = time.time()\n",
    "        cpu_index.add(passage_embedding)\n",
    "        index_time = time.time()\n",
    "        if verbose:\n",
    "            print(f\"Indexing: {index_time-start_time}\")\n",
    "        _, dev_I = cpu_index.search(dev_query_embedding, topN)\n",
    "        search_time = time.time()\n",
    "        if verbose:\n",
    "            print(f\"searching: {search_time-start_time}\")\n",
    "    else:\n",
    "        start_time = time.time()    \n",
    "        _, dev_I = faiss_search_with_gpu_partitioning(passage_embedding, dev_query_embedding, topN)\n",
    "        if verbose:\n",
    "            print(f\"GPU index and search: {time.time()-start_time}\")\n",
    "    \n",
    "    \n",
    "    # evaluation\n",
    "    cuts = [5, 10, 20]\n",
    "    if verbose:\n",
    "        print('eval', task, ckpt_choice)\n",
    "    result = EvalDevQuery(dev_query_embedding2id, passage_embedding2id, dev_query_positive_id, dev_I,\n",
    "                          r_qidmap, r_pidmap,\n",
    "                          topN, run_files_dir, shortcut=False, cuts=cuts)\n",
    "\n",
    "    (prediction, final_ndcg, final_precision, eval_query_cnt,\n",
    "     final_Map, final_mrr, final_recall,\n",
    "     final_recall_100, final_recall_10,\n",
    "     hole_rate_5, hole_rate_20, hole_rate_100,\n",
    "     ms_mrr, Ahole_rate, metrics, prediction) = result\n",
    "    if verbose:\n",
    "        for cut in cuts:\n",
    "            print(f\"NDCG@{cut}:\" + str(final_ndcg[cut]))\n",
    "            print(f\"P@{cut}:\" + str(final_precision[cut]))\n",
    "            print(f\"map@{cut}:\" + str(final_Map[cut]))\n",
    "        print(\"pytrec_mrr:\" + str(final_mrr))\n",
    "        print(\"recall@\"+str(topN)+\":\" + str(final_recall))\n",
    "        print(\"recall@10\"+\":\" + str(final_recall_10))\n",
    "        print(\"recall@100\"+\":\" + str(final_recall_100))\n",
    "        print(\"ms_mrr:\" + str(ms_mrr))\n",
    "    trec_run_fname = dump_pred_to_trecrun(\n",
    "        prediction, run_files_dir, ckpt_choice.replace('/', '__'), r_qidmap, r_pidmap)\n",
    "\n",
    "\n",
    "    # calculate hole rates\n",
    "    labels = defaultdict(dict) # [qid][pid] = 0/1\n",
    "    valid_query = set()\n",
    "    with open(os.path.join(marcoformat_data_dir, 'qrels.tsv')) as fin:\n",
    "        for line in fin:\n",
    "            a = line.strip().split('\\t')\n",
    "            qid, pid, label = a[0], a[2], a[3]\n",
    "            label = 0 if int(label)<=0 else 1\n",
    "            labels[qid][pid] = label\n",
    "            if label==1:\n",
    "                valid_query.add(qid)\n",
    "\n",
    "    cuts = [5, 10, 20, 100]\n",
    "    total, missing = {cut: 0 for cut in cuts}, {cut: 0 for cut in cuts}\n",
    "\n",
    "    run_fname = trec_run_fname  # from previous dense retrieval results\n",
    "    # run_fname = f\"/home/xinji/pseudo-root/rblob/{task}/runs/runs.bm25.txt\"  # bm25\n",
    "    with open(run_fname) as fin:\n",
    "        for line in fin:\n",
    "            a = line.strip().split(' ')\n",
    "            qid, pid, rank = a[0], a[2], int(a[3])\n",
    "            if qid not in valid_query:\n",
    "                continue\n",
    "            for cut in cuts:\n",
    "                if rank <= cut:\n",
    "                    total[cut] += 1\n",
    "                    if qid not in labels or pid not in labels[qid]:\n",
    "                        missing[cut] += 1\n",
    "\n",
    "    if verbose:\n",
    "        for cut in cuts:\n",
    "            print(f'hole@{cut}:', missing[cut]/total[cut])\n",
    "\n",
    "\n",
    "    if verbose:\n",
    "        print('\\n')\n",
    "        print('ndcg@10', final_ndcg[10])\n",
    "        print('recall@100', final_recall_100)\n",
    "        print('hole@10', missing[10]/total[10])\n",
    "    else:\n",
    "        print('{:.4f}\\t{:.4f}\\t{:.4f}'.format(\n",
    "            final_ndcg[10], final_recall_100, missing[10]/total[10]\n",
    "        ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define params below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/treccovid/preprocessed_data/dev-qrel.tsv\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "../inference_output/dev_query_0__emb_p__data_obj_4.pb\n",
      "search\n",
      "(171331, 768) (50, 768)\n",
      "Indexing: 0.12249016761779785\n",
      "searching: 0.3689405918121338\n",
      "eval treccovid modir-treccovid-10k\n",
      "NDCG@5:0.7146378341011254\n",
      "P@5:0.74\n",
      "map@5:0.008810734367829533\n",
      "NDCG@10:0.6761737743183631\n",
      "P@10:0.698\n",
      "map@10:0.015274506169486139\n",
      "NDCG@20:0.6258467684317476\n",
      "P@20:0.6469999999999999\n",
      "map@20:0.02570818829818436\n",
      "pytrec_mrr:0.870468253968254\n",
      "recall@1000:0.3482583404325919\n",
      "recall@10:0.017418426100629346\n",
      "recall@100:0.10514951192393761\n",
      "ms_mrr:{'MRR @10': 0.9495238095238094, 'QueriesRanked': 50}\n",
      "hole@5: 0.16\n",
      "hole@10: 0.192\n",
      "hole@20: 0.244\n",
      "hole@100: 0.411\n",
      "\n",
      "\n",
      "ndcg@10 0.6761737743183631\n",
      "recall@100 0.10514951192393761\n",
      "hole@10 0.192\n"
     ]
    }
   ],
   "source": [
    "# it's advised to do \"restart kernel and run all\" for a new dataset or new checkpoint - to avoid namespace confusion\n",
    "\n",
    "cqa = False\n",
    "data_type = 1 # 0 for document, 1 for passage\n",
    "\n",
    "\n",
    "if not cqa:\n",
    "    task = 'treccovid'\n",
    "    ckpt_choice = f'modir-{task}-10k'\n",
    "    \n",
    "    processed_data_dir = f'../data/{task}/preprocessed_data/'\n",
    "    marcoformat_data_dir = f'../data/{task}/marco-format/'\n",
    "    run_files_dir = f'eval_tmp/'\n",
    "    inference_output_dir = f'../inference_output/'\n",
    "    \n",
    "    end2end(\n",
    "        task,\n",
    "        data_type,\n",
    "        processed_data_dir,\n",
    "        marcoformat_data_dir,\n",
    "        run_files_dir,\n",
    "        inference_output_dir,\n",
    "        verbose=True,\n",
    "    )\n",
    "    \n",
    "else:\n",
    "    subsets = [\n",
    "        'android',\n",
    "        'english',\n",
    "        'gaming',\n",
    "        'gis',\n",
    "        'mathematica',\n",
    "        'physics',\n",
    "        'programmers',\n",
    "        'stats',\n",
    "        'tex',\n",
    "        'unix',\n",
    "        'webmasters',\n",
    "        'wordpress',\n",
    "    ]\n",
    "    \n",
    "    print(f'ndcg\\trec\\thole')\n",
    "    for task in subsets:\n",
    "        ckpt_choice = f'modir-cqadupstack-10k'\n",
    "        \n",
    "        processed_data_dir = f'../data/cqadupstack/{task}/preprocessed_data/'\n",
    "        marcoformat_data_dir = f'../data/cqadupstack/{task}/marco-format/'\n",
    "        run_files_dir = f'eval_tmp/'\n",
    "        inference_output_dir = f'../inference_output/{task}'\n",
    "        \n",
    "        print(task)\n",
    "        end2end(\n",
    "            task,\n",
    "            data_type,\n",
    "            processed_data_dir,\n",
    "            marcoformat_data_dir,\n",
    "            run_files_dir,\n",
    "            inference_output_dir,\n",
    "            verbose=False,\n",
    "        )\n",
    "        print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
